
/*
 * -------------------------------------------------
 *  nf-core/proteogenomicsdb Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */


manifest {
    name            = 'nf-core/proteogenomicsdb'
    contributors    = [
        // TODO nf-core: Update the field with the details of the contributors to your pipeline. New with Nextflow version 24.10.0
        [
            name: 'Alistair Rice',
            affiliation: '',
            email: '',
            github: '',
            contribution: [], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: ''
        ],
        [
            name: ' Hywel Dunn-Davies',
            affiliation: '',
            email: '',
            github: '',
            contribution: [], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: ''
        ],
        [
            name: ' Yasset Perez Riverol',
            affiliation: '',
            email: '',
            github: '',
            contribution: [], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: ''
        ],
        [
            name: ' and Husen M. Umer',
            affiliation: '',
            email: '',
            github: '',
            contribution: [], // List of contribution types ('author', 'maintainer' or 'contributor')
            orcid: ''
        ],
    ]
    homePage        = 'https://github.com/nf-core/proteogenomicsdb'
    description     = """The proteogenomicsdb pipeline (formerly known as pgdb) creates custom protein databases for ProteoGenomics data analysis."""
    mainScript      = 'main.nf'
    defaultBranch   = 'main'
    nextflowVersion = '!>=25.04.0'
    version         = 'dev: 2.0.0'
    doi             = ''
}

singularity {

  enabled      = true
  autoMounts   = true
  envWhitelist = "SINGULARITY_TMPDIR,TMPDIR"
  runOptions   = "-B \$HOME"
  cacheDir     = "/exports/eddie/scratch/s2215490/.cache"

}

plugins {
  id 'nf-google@1.9.0' //allows for the downloading of files off of goole drives
  id 'nf-schema@2.5.1' //validation of pipeline parameters and creation of an input channel from a sample sheet
}

validation {
    defaultIgnoreParams = ["genomes"]
    monochromeLogs = params.monochrome_logs
    help.enabled = true
}


//global default params, used in configs
//container slug. Stable releases should specify release tag!
//developmental code should specify :dev
process.container = 'nfcore/proteogenomicsdb:1.0.0'

//load modules.config for DSL2 module specific options
includeConfig '../conf/modules.config'

//load base.config by default for all pipelines
includeConfig '../conf/base.config'

//load nf-core custom profiles from different institutions                                                                                                                                           â”‚
includeConfig params.custom_config_base && (!System.getenv('NXF_OFFLINE') || !params.custom_config_base.startsWith('http')) ? "${params.custom_config_base}/nfcore_custom.config" : "/dev/null"

profiles {

  conda {
    docker.enabled = false
    singularity.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud = false
    conda.createTimeout = '1 h'
    process.conda = "$projectDir/../environment.yml"
  }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker {
    docker.enabled = true
    singularity.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
    // Avoid this error:
    //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
    // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
    // once this is established and works well, nextflow might implement this behavior as new default.
    docker.runOptions = '-u \$(id -u):\$(id -g)'
  }
  singularity {
    docker.enabled = false
    singularity.enabled = true
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
    singularity.autoMounts = true
  }
  podman {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = true
    shifter.enabled = false
    charliecloud = false
  }
  shifter {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = false
    shifter.enabled = true
    charliecloud.enabled = false
  }
  charliecloud {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = true
  }
  test { includeConfig '../conf/test.config' }
  test_full { includeConfig '../conf/test_full.config' }
  dev { includeConfig '../conf/dev.config' }
}

//export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
  PYTHONNOUSERSITE = 1
  R_PROFILE_USER = "/.Rprofile"
  R_ENVIRON_USER = "/.Renviron"
}

//capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.html"
}


//function to ensure that resource requirements don't go beyond a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}